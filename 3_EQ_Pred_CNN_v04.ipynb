{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EQ_Pred_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C13MaN2i3J1"
      },
      "source": [
        "This is a follow up of the preprocessing notebook, written by Arad HamidSamiee.\n",
        "\n",
        "---\n",
        "\n",
        "#Earthquake Magnitude Prediction#\n",
        "(part 3 / 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zDbNBuvO0OA"
      },
      "source": [
        "!rm -rf BaseData"
      ],
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdgBla6nqnrA"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, optimizers, regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # will be utelized to label images"
      ],
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-qGcbb6hHP7"
      },
      "source": [
        "!unzip BaseData.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dv680rihI42"
      },
      "source": [
        "train = ImageDataGenerator()\n",
        "validation = ImageDataGenerator()\n",
        "\n",
        "train_dataset = train.flow_from_directory(directory = \"BaseData/train/\",\n",
        "                                          target_size = (256,256),\n",
        "                                          batch_size = 3,\n",
        "                                          class_mode = 'binary')\n",
        "\n",
        "validation_dataset = train.flow_from_directory(directory = \"BaseData/validation/\",\n",
        "                                          target_size = (256,256),\n",
        "                                          batch_size = 3,\n",
        "                                          class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70vlVVR-jr8z"
      },
      "source": [
        "print(train_dataset.class_indices, validation_dataset.class_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK-K3D5_junv"
      },
      "source": [
        "train_dataset.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW-OGcD5qW8e"
      },
      "source": [
        "model = models.Sequential([\n",
        "                           layers.Conv2D(filters=8, kernel_size=(5,5), strides=(1,1), activation='relu'),\n",
        "                           layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "                           \n",
        "                           layers.Conv2D(filters=8, kernel_size=(5,5), strides=(1,1), activation='relu'),\n",
        "                           layers.AvgPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "                           layers.Conv2D(filters=8, kernel_size=(5,5), strides=(1,1), activation='relu'),\n",
        "                           layers.AvgPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "                           layers.Dropout(rate=0.5),\n",
        "                           layers.Dropout(rate=0.5),\n",
        "\n",
        "                           layers.Flatten(),\n",
        "\n",
        "                           layers.Dense(512, 'relu', kernel_regularizer = regularizers.L2(0.0005), bias_regularizer = regularizers.L2(0.0005)),\n",
        "                           layers.Dense(1,'relu', kernel_regularizer = regularizers.L2(0.0005), bias_regularizer = regularizers.L2(0.0005))\n",
        "                           ])"
      ],
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EeXh4Rjxd4T"
      },
      "source": [
        "opt = optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=opt)\n",
        "# L1 : laplace\n",
        "# l2 : Gaussian\n",
        "# L2 = Weight Decay"
      ],
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCUErEky7upc"
      },
      "source": [
        "model_fit = model.fit(train_dataset,\n",
        "                      steps_per_epoch = 3,\n",
        "                      epochs = 500,\n",
        "                      validation_data = validation_dataset\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOs6qE9Qzq0f"
      },
      "source": [
        "validation_dataset.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufXSGvkv9rAq"
      },
      "source": [
        "TestDataPath = 'BaseData/test'\n",
        "for i in os.listdir(TestDataPath):\n",
        "    img = image.load_img(TestDataPath+'//'+i, target_size=(256,256))\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    print(TestDataPath+'//'+i)\n",
        "    X = image.img_to_array(img)\n",
        "    X = np.expand_dims(X, axis=0)\n",
        "    images = np.vstack([X])\n",
        "    label = model.predict(images)\n",
        "    if label == 1:\n",
        "        print(math.floor(label[0][0]), \"Oh oh, That's BAD news! O_o \\n\")\n",
        "    else:\n",
        "        print(math.floor(label[0][0]), \"You'll be fine.\\n\")\n",
        "    # elif label == 1:\n",
        "    #     print(label, \"Oh oh, That's BAD news!\\n\")\n",
        "    # else:\n",
        "    #     print(label,\"\\nABOMINATION!!!\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}